{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1386fd6a",
   "metadata": {},
   "source": [
    "# **Lab 11: Image Classification with Convolutional Neural Networks (CNNs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3a3266",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db885f23",
   "metadata": {},
   "source": [
    "The new package this week is `torchvision`, as it depends on Pytorch and their versions need to be compatible, unistall your torch version and then reinstall known compatible versions of both packages with either pip or conda with the code as shown below:\n",
    "\n",
    "\n",
    "`conda install pytorch==2.1.0 torchvision==0.16.0 -c pytorch`\n",
    "\n",
    "(`pip install torch==2.1.0 torchvision==0.16.0` if you prefer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187f5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad1ec21",
   "metadata": {},
   "source": [
    "Here again we have the code to select device, CPU is plenty for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ece97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c91ea",
   "metadata": {},
   "source": [
    "### Loading and Exploring the MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65872a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# Load the full training set\n",
    "train_val_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# Split: 90% train, 10% validation\n",
    "train_size = int(0.9 * len(train_val_dataset))\n",
    "val_size = len(train_val_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Test set\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d97ca0",
   "metadata": {},
   "source": [
    "Let's display 5 example images from the dataset with their labels, to get an idea of what they look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f4c225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples) # Get one batch of training data\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Label: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d5a1e6",
   "metadata": {},
   "source": [
    "## Defining a Simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a0ed8",
   "metadata": {},
   "source": [
    "### Understanding the CNN Architecture\n",
    "\n",
    "Let's break down the `SimpleCNN` model below to understand how each layer works and why specific hyperparameters are chosen.\n",
    "\n",
    "#### ðŸ”¹ Convolutional Layer 1\n",
    "```python\n",
    "nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "```\n",
    "- **Input channels**: 1 (grayscale MNIST images).\n",
    "- **Output channels**: 16. This means we are learning 16 different filters/features from the input.\n",
    "- **Kernel size**: 3Ã—3. A small receptive field that captures local patterns like edges.\n",
    "- **Padding**: 1. This ensures the output feature map has the same spatial dimensions as the input (28Ã—28), preserving edge information.\n",
    "\n",
    "#### ðŸ”¹ Activation Function: ReLU\n",
    "```python\n",
    "nn.ReLU()\n",
    "```\n",
    "- Introduces non-linearity, allowing the model to learn more complex patterns.\n",
    "- ReLU replaces all negative values with zero, helping avoid vanishing gradients.\n",
    "\n",
    "#### ðŸ”¹ Max Pooling Layer 1\n",
    "```python\n",
    "nn.MaxPool2d(2)\n",
    "```\n",
    "- **Kernel size**: 2Ã—2.\n",
    "- **Effect**: Downsamples the feature map by a factor of 2 (from 28Ã—28 to 14Ã—14).\n",
    "- This reduces spatial dimensions and computational cost, while retaining important features.\n",
    "\n",
    "---\n",
    "\n",
    "#### ðŸ”¹ Convolutional Layer 2\n",
    "```python\n",
    "nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "```\n",
    "- **Input channels**: 16 (output from previous layer).\n",
    "- **Output channels**: 32. We are now learning 32 higher-level features.\n",
    "- **Kernel size and padding**: Same as before to preserve spatial size pre-pooling.\n",
    "\n",
    "#### ðŸ”¹ Activation Function and Max Pooling Layer 2\n",
    "```python\n",
    "nn.ReLU(), nn.MaxPool2d(2)\n",
    "```\n",
    "- Again apply ReLU followed by 2Ã—2 max pooling.\n",
    "- **Resulting dimensions**: The 14Ã—14 feature maps become 7Ã—7, with 32 channels.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¸ Fully Connected Layers\n",
    "\n",
    "Before we can use fully connected (dense) layers, we need to **flatten** the 3D tensor output from the convolutional layers:\n",
    "- From shape: `(batch_size, 32, 7, 7)`\n",
    "- To shape: `(batch_size, 32 * 7 * 7) = (batch_size, 1568)`\n",
    "\n",
    "```python\n",
    "nn.Flatten(),\n",
    "nn.Linear(32 * 7 * 7, 100),\n",
    "nn.ReLU()\n",
    "```\n",
    "- **First Linear Layer**:\n",
    "  - Input: 1568 features.\n",
    "  - Output: 100 neurons.\n",
    "  - Acts as a classic MLP hidden layer to mix the features.\n",
    "\n",
    "```python\n",
    "nn.Linear(100, 10)\n",
    "```\n",
    "- Final layer that maps the 100 features to **10 output classes** (digits 0 through 9).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2273fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 7 * 7, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer(x)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1460dcc4",
   "metadata": {},
   "source": [
    "Instantiate the model, move it to the device, and print the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c3fb01",
   "metadata": {},
   "source": [
    "## Creating a training and testing loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbbfdc0",
   "metadata": {},
   "source": [
    "As with last week we create loops for training and testing specific to this dataset and the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5a1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.to(device)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        train_acc = 100 * correct / total\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validation loss\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "        \n",
    "def evaluate_model(model, data_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e34e86f",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea39b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleCNN()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses = train_model(model, train_loader, val_loader, optimizer, criterion, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3533bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d77258",
   "metadata": {},
   "source": [
    "### Evaluating and Visualising Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b74387",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = evaluate_model(model, test_loader)\n",
    "print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56228e43",
   "metadata": {},
   "source": [
    "Displaying 10 test images with predicted and actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47527cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data, example_targets = example_data.to(device), example_targets.to(device)\n",
    "\n",
    "output = model(example_data)\n",
    "_, preds = torch.max(output, 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0].cpu(), cmap='gray', interpolation='none')\n",
    "    plt.title(f\"Pred: {preds[i]}, True: {example_targets[i]}\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd999729",
   "metadata": {},
   "source": [
    "# Your Task: Improve on this model!\n",
    "\n",
    "As with last week I want you to try mess with this model to get a sense of how changing the parameters can improve, or break the model.\n",
    "\n",
    "Here are some basic suggestions, but feel free to look online for even more suggestions on things you can change! (Try not to just copy in other architectures completely, but instead incorporate elements they have into our model.)\n",
    "\n",
    "- **Network Architecture**\n",
    "  - Add an extra convolutional layer\n",
    "  - Increase or decrease number of filters (e.g. 32 â†’ 64)\n",
    "  - Change kernel size (e.g. 3Ã—3 â†’ 5Ã—5)\n",
    "  - Use more fully connected layers or increase hidden units\n",
    "\n",
    "- **Regularization**\n",
    "  - Add Dropout after conv or linear layers\n",
    "  - Apply L2 weight decay via the optimizer\n",
    "\n",
    "- **Training Settings**\n",
    "  - Switch optimizer (SGD + momentum, AdamW)\n",
    "  - Change learning rate\n",
    "\n",
    "- **Activation Functions**\n",
    "  - Try LeakyReLU, ELU, Sigmoid or GELU instead of ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1491cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
